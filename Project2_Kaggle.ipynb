{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Personalized Page Rank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Members: Peter Weber, Huang Chen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cProfile\n",
    "from IPython.core.debugger import set_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>item_id</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-9.912859</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-8.459001</td>\n",
       "      <td>-9.753888</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.489137</td>\n",
       "      <td>4.388006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.833517</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.245176</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.463533</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.866705</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-4.101858</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.853917</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.894698</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.869197</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.381025</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "item_id       1    2         3         4         5         6         7    \\\n",
       "user_id                                                                    \n",
       "0             NaN  NaN -9.912859       NaN       NaN -8.459001 -9.753888   \n",
       "1             NaN  NaN  5.489137  4.388006       NaN       NaN       NaN   \n",
       "2             NaN  NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "3             NaN  NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "4        8.866705  NaN -4.101858       NaN  0.853917       NaN       NaN   \n",
       "\n",
       "item_id       8         9    10  ...   91   92        93   94   95   96   \\\n",
       "user_id                          ...                                       \n",
       "0             NaN       NaN  NaN ...   NaN  NaN       NaN  NaN  NaN  NaN   \n",
       "1             NaN  8.833517  NaN ...   NaN  NaN  0.245176  NaN  NaN  NaN   \n",
       "2             NaN       NaN  NaN ...   NaN  NaN       NaN  NaN  NaN  NaN   \n",
       "3        6.463533       NaN  NaN ...   NaN  NaN       NaN  NaN  NaN  NaN   \n",
       "4        3.894698       NaN  NaN ...   NaN  NaN       NaN  NaN  NaN  NaN   \n",
       "\n",
       "item_id       97   98        99   100  \n",
       "user_id                                \n",
       "0             NaN  NaN       NaN  NaN  \n",
       "1             NaN  NaN       NaN  NaN  \n",
       "2             NaN  NaN       NaN  NaN  \n",
       "3             NaN  NaN       NaN  NaN  \n",
       "4        2.869197  NaN  1.381025  NaN  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data = pd.read_csv('./data/training.csv', sep=',')\n",
    "\n",
    "urm = pd.pivot_table(training_data[['user_id','item_id','rating']],columns='item_id',index='user_id',values='rating')\n",
    "urm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13291</td>\n",
       "      <td>98</td>\n",
       "      <td>-0.670408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19559</td>\n",
       "      <td>8</td>\n",
       "      <td>1.436404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32928</td>\n",
       "      <td>50</td>\n",
       "      <td>1.711739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34459</td>\n",
       "      <td>29</td>\n",
       "      <td>-10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>68339</td>\n",
       "      <td>19</td>\n",
       "      <td>4.277970</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id     rating\n",
       "0    13291       98  -0.670408\n",
       "1    19559        8   1.436404\n",
       "2    32928       50   1.711739\n",
       "3    34459       29 -10.000000\n",
       "4    68339       19   4.277970"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([72797, 63003, 63003, 67871, 67871, 48845, 54070, 70413, 70413,\n",
       "       63176, 63176, 64052, 66872, 57741, 57741, 56801, 53899, 62624,\n",
       "       57485, 53066, 63480, 66606, 66606, 49873, 58710])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_user_items = pd.read_csv('./data/target_user_items.csv')\n",
    "target_user_items.shape\n",
    "\n",
    "target_user_items.head()\n",
    "\n",
    "target_users = target_user_items.user_id.values\n",
    "train_users = training_data.user_id.values\n",
    "\n",
    "missing_users_bool = np.array((1-np.in1d(target_users, train_users)), dtype = bool)\n",
    "missing_users = target_users[missing_users_bool]\n",
    "missing_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  rating\n",
       "0   0       0\n",
       "1   1       0\n",
       "2   2       0\n",
       "3   3       0\n",
       "4   4       0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission = pd.read_csv('./data/submision_sample.csv')\n",
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper funcitons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_rmse(y_pred, y_true):\n",
    "    \"\"\" Compute Root Mean Squared Error. \"\"\"\n",
    "    return np.sqrt(np.mean(np.power(y_pred - y_true, 2)))\n",
    "\n",
    "def index2user(index, UI):\n",
    "    user_index = np.arange(len(UI.index))\n",
    "    users = dict(zip(user_index,UI.index))\n",
    "    return(users[index])\n",
    "\n",
    "def user2index(user, UI):\n",
    "    user_index = np.arange(len(UI.index))\n",
    "    user_index2id = dict(zip(UI.index, user_index))\n",
    "    return(user_index2id[user])\n",
    "\n",
    "def index2item(index, UI):\n",
    "    item_index = np.arange(len(UI.columns))\n",
    "    items = dict(zip(item_index,UI.columns))\n",
    "    return(items[index])\n",
    "\n",
    "def item2index(item, UI):\n",
    "    item_index = np.arange(len(UI.columns))\n",
    "    item_index2id = dict(zip(UI.columns, item_index))\n",
    "    return(item_index2id[item])\n",
    "\n",
    "#index2item(99, urm)\n",
    "#item2index(100, urm)\n",
    "#index2user(73338, urm)\n",
    "#user2index(73420, urm)\n",
    "user2index(0,urm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we construct the matrix S which we later use to build the restart vector.\n",
    "def construct_pagerank_matrix_weighted(UI):\n",
    "    \"\"\"\n",
    "    input\n",
    "        - UI: User-Item matrix\n",
    "    output\n",
    "        - UI and UI_T, both column stochastic, and with values between 0 and 1\n",
    "    \"\"\"\n",
    "    ## Normalize to values between 0 and 1\n",
    "    UI_fill = UI.fillna(UI.min())    \n",
    "    UI_norm = UI_fill + abs(UI.min())\n",
    "    \n",
    "    ## Make matrix column stochastic\n",
    "    col_sums = UI_norm.sum(axis = 0)\n",
    "    row_sums = UI_norm.sum(axis = 1)\n",
    "    UI_col_stoch = UI_norm/col_sums\n",
    "    UI_T_col_stoch = (UI_norm.T)/row_sums\n",
    "    \n",
    "    return(UI_col_stoch.fillna(0), UI_T_col_stoch.fillna(0))\n",
    "\n",
    "# We contrust the matrix A.\n",
    "def construct_pagerank_matrix_binary(UI):\n",
    "    \"\"\"\n",
    "    input\n",
    "        - UI: User-Item matrix\n",
    "    output\n",
    "        - UI and UI_T, both column stochastic, and having all equal values per column\n",
    "    \"\"\"\n",
    "    UI_binary = UI.notnull().astype('int')\n",
    "    \n",
    "    ## Make matrix column stochastic\n",
    "    col_sums = UI_binary.sum(axis = 0)\n",
    "    row_sums = UI_binary.sum(axis = 1)\n",
    "\n",
    "    UI_col_stoch = UI_binary/col_sums\n",
    "    UI_T_col_stoch = (UI_binary.T)/row_sums\n",
    "    \n",
    "    return(UI_col_stoch.fillna(0), UI_T_col_stoch.fillna(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Power Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With the given matrix A,At and the restart vector from the matrix S, \n",
    "# we use Power Method to compute similarity between users\n",
    "def solve_power_method_uu(A, A_T, restart_vec, alpha, tol, max_iter = 1000, print_conv = False):\n",
    "    \"\"\"\n",
    "    There are two systems of equations, the first is the upper right from lectures\n",
    "    and the second is the lower left from lectures\n",
    "    Solve them separately and restart in the item step\n",
    "    \n",
    "    Inputs\n",
    "        - A: pagerank matrix, column stochastic \n",
    "        - A_T: its inverse, column stochastic\n",
    "        - restart vec: user individual restart vector\n",
    "        \n",
    "    Outputs\n",
    "        - x_u_p1: user_vector of most similar users\n",
    "        - x_i_p1: item_vector of most liked items for user defined by restart vector\n",
    "    \"\"\"\n",
    "    #set_trace()\n",
    "    \n",
    "    iter_ = 0\n",
    "    users, items = A.shape\n",
    "    \n",
    "    ## TODO: user initialization vector from user\n",
    "    x_u = np.random.random((users,1))\n",
    "    x_u = x_u/np.linalg.norm(x_u)\n",
    "    \n",
    "    while iter_ <= max_iter:\n",
    "        iter_ += 1\n",
    "        ## computation upper right\n",
    "        x_u_p1 = A.dot((1-alpha) * A_T.dot(x_u) + alpha * restart_vec)\n",
    "        x_u_p1 = x_u_p1/np.linalg.norm(x_u_p1)\n",
    "        \n",
    "        ##Â calculate iter error\n",
    "        error = np.linalg.norm(x_u - x_u_p1)\n",
    "        \n",
    "        ## convergence criteria\n",
    "        if error < tol:\n",
    "            if print_conv:\n",
    "                print(\"Convergence!\")\n",
    "            break\n",
    "            \n",
    "        if iter_ == max_iter:\n",
    "            print(\"PM did not converge!!!\")\n",
    "         \n",
    "        ## set intial values in loop\n",
    "        x_u = x_u_p1\n",
    "        \n",
    "    return(x_u_p1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solve personalized pagerank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method that construct the necesary matrices and then use them to calculate users similarities vector for each user.\n",
    "def solve_PPR_uu(UI, user_ids, alpha, tol, missing_users):\n",
    "    \"\"\"\n",
    "    inputs:\n",
    "        - UI: user-item matrix\n",
    "        - user_ids: all user_ids of set that we want to predict\n",
    "        - alpha: weight param in power method\n",
    "        - tol: tolerance\n",
    "        - missing_users: users that exist in target set but not in training set\n",
    "        \n",
    "    outputs:\n",
    "        - user_similarity: user similiraity matrix for all users in target/prediction set\n",
    "    \"\"\"    \n",
    "        \n",
    "        \n",
    "    num_users, num_items = UI.shape\n",
    "    \n",
    "    ## Pagerang matrix\n",
    "    A, A_T = construct_pagerank_matrix_binary(UI)  \n",
    "    A, A_T = A.values.copy(), A_T.values.copy()\n",
    "    \n",
    "    ## Personalization matrix for restart vector\n",
    "    _, E_T = construct_pagerank_matrix_weighted(UI)\n",
    "    E_T = E_T.values.copy()\n",
    "    \n",
    "    user_similarity = {}\n",
    "    \n",
    "    counter = 0\n",
    "    \n",
    "    existing_users = set(user_ids) - set(missing_users)\n",
    "    \n",
    "    for user in existing_users:\n",
    "        counter += 1\n",
    "                    \n",
    "        if float(counter % 100) == 0.0:\n",
    "            print(counter)\n",
    "        index = user2index(user, UI)\n",
    "        \n",
    "        ## restart vector\n",
    "        restart_vec = E_T[:,index]\n",
    "        restart_vec = restart_vec.reshape(-1 ,1)\n",
    "        \n",
    "        x_u = solve_power_method_uu(A, A_T, restart_vec, alpha, tol)\n",
    "        user_similarity[user] = x_u.flatten()\n",
    "    return(user_similarity)\n",
    "\n",
    "#user_ids = urm.index[0:-1:10000]\n",
    "#user_sim = solve_PPR_uu(urm, user_ids, 0.5, 1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_k_most_similar_users_dict(user_id, user_sim, UI, k, return_indices = True):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "        - user_id: id of user in UI\n",
    "        - UU: User-user similarity matrix, output of solve_PPR_uu\n",
    "        - UI: user-item matrix\n",
    "        - k: number of most similar users\n",
    "    Outputs:\n",
    "        - user_array: array of similarity scores for user with user_idx\n",
    "        - sorted_users: user_ids of k most similar users\n",
    "    \"\"\"\n",
    "    #user_idx = user2index(user_id, UI)\n",
    "    user_sim_array = user_sim[user_id]\n",
    "    sorted_indices = user_sim_array.argsort()[-k:][::-1]\n",
    "    if return_indices:\n",
    "        return(user_sim_array, np.array(sorted_indices))\n",
    "    else:\n",
    "        sorted_users = [index2user(u_idx, UI) for u_idx in sorted_indices]\n",
    "        return(user_sim_array, np.array(sorted_users))\n",
    "    \n",
    "#get_k_most_similar_users_dict(10000, user_sim, urm, k = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_dict(user_id, item_id, user_sim, UI, k, missing_users):\n",
    "    \"\"\"\n",
    "    This prediction function uses standard prediction equation such as Eq. 2.2\n",
    "    on page 52 in Aggarwal, Recommender Systems\n",
    "    \n",
    "    inputs:\n",
    "        - user_id, item_id\n",
    "        - user_sim: output of solve_PPR_uu\n",
    "        - UI: user-item matrix from dataset\n",
    "        - k: most similar users\n",
    "        - missing_users: user that exist in the target set, but not in the training set\n",
    "        \n",
    "    output:\n",
    "        - rating for given user_id, item_id\n",
    "    \"\"\"\n",
    "    \n",
    "    if user_id in missing_users:\n",
    "        return(pd.Series(0))\n",
    "    \n",
    "    similarities, user_indices = get_k_most_similar_users_dict(user_id, user_sim, UI, k)\n",
    "    user_idx = user2index(user_id, UI)\n",
    "    item_idx = item2index(item_id, UI)\n",
    "    \n",
    "    rating_num = 0.0\n",
    "    rating_den = 0.0\n",
    "    \n",
    "    user_mean = UI[UI.index == user_id].mean(skipna = True, axis = 1)\n",
    "\n",
    "    for other_idx in user_indices:\n",
    "        if other_idx == user_idx: continue\n",
    "        other_mean = UI.iloc[other_idx, :].mean(skipna = True)\n",
    "        other_rating = UI.iloc[other_idx, item_idx]\n",
    "        if not pd.isnull(other_rating):\n",
    "            rating_num += similarities[other_idx] * (other_rating - other_mean)\n",
    "        rating_den += similarities[other_idx]\n",
    "    \n",
    "    if rating_den == 0.0 or rating_num == 0.0:\n",
    "        prediction = user_mean\n",
    "    else:\n",
    "        prediction = user_mean + rating_num/rating_den\n",
    "    return(prediction)\n",
    "\n",
    "\n",
    "#cProfile.run('predict(1, 1, user_user, urm)')\n",
    "#predict_dict(user_id = 10000, item_id = 1, user_sim = user_sim, UI = urm, k = 100, missing_users = missing_users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, test = train_test_split(training_data, test_size = 0.0005, random_state = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(475, 3)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>item_id</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-9.912859</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-8.459001</td>\n",
       "      <td>-9.753888</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.489137</td>\n",
       "      <td>4.388006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.833517</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.245176</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.463533</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.866705</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-4.101858</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.853917</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.894698</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.869197</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.381025</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "item_id       1    2         3         4         5         6         7    \\\n",
       "user_id                                                                    \n",
       "0             NaN  NaN -9.912859       NaN       NaN -8.459001 -9.753888   \n",
       "1             NaN  NaN  5.489137  4.388006       NaN       NaN       NaN   \n",
       "2             NaN  NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "3             NaN  NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "4        8.866705  NaN -4.101858       NaN  0.853917       NaN       NaN   \n",
       "\n",
       "item_id       8         9    10  ...   91   92        93   94   95   96   \\\n",
       "user_id                          ...                                       \n",
       "0             NaN       NaN  NaN ...   NaN  NaN       NaN  NaN  NaN  NaN   \n",
       "1             NaN  8.833517  NaN ...   NaN  NaN  0.245176  NaN  NaN  NaN   \n",
       "2             NaN       NaN  NaN ...   NaN  NaN       NaN  NaN  NaN  NaN   \n",
       "3        6.463533       NaN  NaN ...   NaN  NaN       NaN  NaN  NaN  NaN   \n",
       "4        3.894698       NaN  NaN ...   NaN  NaN       NaN  NaN  NaN  NaN   \n",
       "\n",
       "item_id       97   98        99   100  \n",
       "user_id                                \n",
       "0             NaN  NaN       NaN  NaN  \n",
       "1             NaN  NaN       NaN  NaN  \n",
       "2             NaN  NaN       NaN  NaN  \n",
       "3             NaN  NaN       NaN  NaN  \n",
       "4        2.869197  NaN  1.381025  NaN  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def set_test_ratings_to_na(UI, test):\n",
    "    UI_ = UI.copy()\n",
    "    counter = 0\n",
    "    for user_id, item_id in zip(test.user_id.values, test.item_id.values):\n",
    "        counter += 1\n",
    "        user_idx = user2index(user_id, UI)\n",
    "        item_idx = item2index(item_id, UI)\n",
    "        UI_.iloc[user_idx, item_idx] = np.NaN\n",
    "        if float(counter % 100.0) == 0.0:\n",
    "            print(counter)\n",
    "    return(UI_)    \n",
    "\n",
    "train = set_test_ratings_to_na(urm, test)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n"
     ]
    }
   ],
   "source": [
    "user_user = solve_PPR_uu(train, user_ids = test.user_id, alpha = 0.1, tol = 1e-8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_ratings_on_test_set(test, user_user_sim, k):\n",
    "    \"\"\"\n",
    "    inputs:\n",
    "        - test: test_set or set to predict on\n",
    "        - user_user_sim: output of solve_PPR_uu\n",
    "        \n",
    "    outputs:\n",
    "        rating_pred: vector of ratings for test set\n",
    "    \n",
    "    \"\"\"\n",
    "    rating_pred = []\n",
    "    counter = 0\n",
    "    for user_id, item_id in zip(test.user_id, test.item_id):\n",
    "        counter += 1\n",
    "        rating_pred.append(predict_dict(user_id, item_id, user_user_sim, train, k, missing_users).max(skipna=True))\n",
    "        if float(counter % 200) == 0.0:\n",
    "            print(counter)\n",
    "    return(rating_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "400\n"
     ]
    }
   ],
   "source": [
    "rating_pred_ = predict_ratings_on_test_set(test, user_user, k = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.4993274909401872"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.rating\n",
    "compute_rmse(rating_pred_, test.rating)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_user_submission = solve_PPR_uu(urm, user_ids = target_user_items.user_id, alpha = 0.2, tol = 1e-6, \n",
    "                                    missing_users = missing_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "400\n",
      "600\n",
      "800\n",
      "1000\n",
      "1200\n",
      "1400\n",
      "1600\n",
      "1800\n",
      "2000\n",
      "2200\n",
      "2400\n",
      "2600\n",
      "2800\n",
      "3000\n",
      "3200\n",
      "3400\n",
      "3600\n",
      "3800\n",
      "4000\n",
      "4200\n",
      "4400\n",
      "4600\n",
      "4800\n",
      "5000\n",
      "5200\n",
      "5400\n",
      "5600\n",
      "5800\n",
      "6000\n",
      "6200\n",
      "6400\n",
      "6600\n",
      "6800\n",
      "7000\n",
      "7200\n",
      "7400\n",
      "7600\n",
      "7800\n",
      "8000\n",
      "8200\n",
      "8400\n",
      "8600\n",
      "8800\n",
      "9000\n",
      "9200\n",
      "9400\n",
      "9600\n",
      "9800\n",
      "10000\n",
      "10200\n",
      "10400\n",
      "10600\n",
      "10800\n",
      "11000\n",
      "11200\n",
      "11400\n",
      "11600\n",
      "11800\n",
      "12000\n",
      "12200\n",
      "12400\n",
      "12600\n",
      "12800\n",
      "13000\n",
      "13200\n",
      "13400\n",
      "13600\n",
      "13800\n",
      "14000\n",
      "14200\n",
      "14400\n",
      "14600\n",
      "14800\n",
      "15000\n",
      "15200\n",
      "15400\n",
      "15600\n",
      "15800\n",
      "16000\n",
      "16200\n",
      "16400\n",
      "16600\n",
      "16800\n",
      "17000\n",
      "17200\n",
      "17400\n",
      "17600\n",
      "17800\n",
      "18000\n",
      "18200\n",
      "18400\n",
      "18600\n",
      "18800\n",
      "19000\n",
      "19200\n",
      "19400\n",
      "19600\n",
      "19800\n",
      "20000\n",
      "20200\n",
      "20400\n",
      "20600\n",
      "20800\n",
      "21000\n",
      "21200\n",
      "21400\n",
      "21600\n",
      "21800\n",
      "22000\n",
      "22200\n",
      "22400\n",
      "22600\n",
      "22800\n",
      "23000\n",
      "23200\n",
      "23400\n",
      "23600\n",
      "23800\n",
      "24000\n",
      "24200\n",
      "24400\n",
      "24600\n",
      "24800\n",
      "25000\n",
      "25200\n",
      "25400\n",
      "25600\n",
      "25800\n",
      "26000\n",
      "26200\n",
      "26400\n",
      "26600\n",
      "26800\n",
      "27000\n",
      "27200\n",
      "27400\n",
      "27600\n",
      "27800\n",
      "28000\n",
      "28200\n",
      "28400\n",
      "28600\n",
      "28800\n",
      "29000\n",
      "29200\n",
      "29400\n",
      "29600\n",
      "29800\n",
      "30000\n",
      "30200\n",
      "30400\n",
      "30600\n",
      "30800\n",
      "31000\n",
      "31200\n",
      "31400\n",
      "31600\n",
      "31800\n",
      "32000\n",
      "32200\n",
      "32400\n",
      "32600\n",
      "32800\n",
      "33000\n",
      "33200\n",
      "33400\n",
      "33600\n",
      "33800\n",
      "34000\n",
      "34200\n",
      "34400\n",
      "34600\n",
      "34800\n",
      "35000\n",
      "35200\n",
      "35400\n",
      "35600\n",
      "35800\n",
      "36000\n",
      "36200\n",
      "36400\n",
      "36600\n",
      "36800\n",
      "37000\n",
      "37200\n",
      "37400\n",
      "37600\n",
      "37800\n",
      "38000\n",
      "38200\n",
      "38400\n",
      "38600\n",
      "38800\n",
      "39000\n",
      "39200\n",
      "39400\n",
      "39600\n",
      "39800\n",
      "40000\n",
      "40200\n",
      "40400\n",
      "40600\n",
      "40800\n",
      "41000\n",
      "41200\n",
      "41400\n",
      "41600\n",
      "41800\n",
      "42000\n",
      "42200\n",
      "42400\n",
      "42600\n",
      "42800\n",
      "43000\n",
      "43200\n",
      "43400\n",
      "43600\n",
      "43800\n",
      "44000\n",
      "44200\n",
      "44400\n",
      "44600\n",
      "44800\n",
      "45000\n",
      "45200\n",
      "45400\n",
      "45600\n",
      "45800\n",
      "46000\n",
      "46200\n",
      "46400\n",
      "46600\n",
      "46800\n",
      "47000\n",
      "47200\n",
      "47400\n",
      "47600\n",
      "47800\n",
      "48000\n",
      "48200\n",
      "48400\n",
      "48600\n",
      "48800\n",
      "49000\n",
      "49200\n",
      "49400\n",
      "49600\n",
      "49800\n",
      "50000\n"
     ]
    }
   ],
   "source": [
    "rating_submission = predict_ratings_on_test_set(target_user_items, user_user_submission, k = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>49995</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>49996</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>49997</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>49998</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>49999</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  rating\n",
       "49995  49995       0\n",
       "49996  49996       0\n",
       "49997  49997       0\n",
       "49998  49998       0\n",
       "49999  49999       0"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>49995</td>\n",
       "      <td>1.111051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>49996</td>\n",
       "      <td>0.256974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>49997</td>\n",
       "      <td>3.883351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>49998</td>\n",
       "      <td>1.377812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>49999</td>\n",
       "      <td>-0.074726</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id    rating\n",
       "49995  49995  1.111051\n",
       "49996  49996  0.256974\n",
       "49997  49997  3.883351\n",
       "49998  49998  1.377812\n",
       "49999  49999 -0.074726"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.DataFrame({\n",
    "    'id': np.arange(sample_submission.shape[0]),\n",
    "    'rating': rating_submission\n",
    "})\n",
    "\n",
    "submission.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This gave our Kaggle result of 4.69"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Item-item based CF\n",
    "\n",
    "**We use this as base line. Item-item CF gave us 4.80 on Kaggle! **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(150000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 150 seconds\n"
     ]
    }
   ],
   "source": [
    "# Use the movielens dataset with 100,000 ratings\n",
    "%autosave 150\n",
    "%matplotlib inline\n",
    "import operator\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import matplotlib.pyplot as plt; plt.rcdefaults()\n",
    "import cProfile\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of items\n",
    "N = 10\n",
    "# Number of nearest neighbors\n",
    "NN = N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "def pearson_similarity_items(df, item1, item2, min_common_users=1):\n",
    "    \"\"\"\n",
    "    Returns a Pearson correlation score for item1 and item2\n",
    "    \"\"\"    \n",
    "     #Â GET USERS OF ITEM1\n",
    "    users_item1 = df[df['item_id'] == item1]\n",
    "    # GET USERS OF ITEM2\n",
    "    users_item2 = df[df['item_id'] == item2]\n",
    "    \n",
    "    #Â FIND SHARED USERS\n",
    "    users_common = pd.merge(users_item1, users_item2, on = 'user_id')\n",
    "    if len(users_common)==0:\n",
    "        return 0    \n",
    "    if len(users_common)<min_common_users:\n",
    "        return 0    \n",
    "    corr=pearsonr(users_common['rating_x'],users_common['rating_y'])[0]\n",
    "    if np.isnan(corr):\n",
    "        return 0\n",
    "    return corr\n",
    "\n",
    "def cos_similarity_items(df, item1, item2, min_common_users=1):\n",
    "    \"\"\"\n",
    "    Returns a cosine similarity score for item1 and item2\n",
    "    \"\"\"        \n",
    "    #Â GET USERS OF ITEM1\n",
    "    users_item1 = df[df['item_id'] == item1]\n",
    "    \n",
    "    # GET USERS OF ITEM2\n",
    "    users_item2 = df[df['item_id'] == item2]\n",
    "    \n",
    "    #Â FIND SHARED USERS\n",
    "    users_common = pd.merge(users_item1, users_item2, on = 'user_id')\n",
    "    if len(users_common)==0:\n",
    "        return 0    \n",
    "    if(len(users_common)<min_common_users):\n",
    "        return 0  \n",
    "\n",
    "    num = users_common['rating_x'].dot(users_common['rating_y'])\n",
    "    den = np.sqrt(users_common['rating_x'].dot(users_common['rating_x'])*\\\n",
    "                  users_common['rating_y'].dot(users_common['rating_y']))\n",
    "    cos_sim = num/den\n",
    "    if(np.isnan(cos_sim)):\n",
    "        return 0\n",
    "    return cos_sim\n",
    "\n",
    "\n",
    "def adjcos_similarity_items(df_, item1, item2, min_common_users=1):\n",
    "    \"\"\"\n",
    "    Returns an adjusted cosine similarity score for item1 and item2\n",
    "    \"\"\"\n",
    "    df = df_.copy()\n",
    "    user_means = df.groupby(['user_id'], axis=0)['rating'].transform('mean')\n",
    "    df['rating'] = df['rating'] - user_means\n",
    "    \n",
    "    #Â GET USERS OF ITEM1\n",
    "    users_item1 = df[df['item_id'] == item1]\n",
    "    \n",
    "    # GET USERS OF ITEM2\n",
    "    users_item2 = df[df['item_id'] == item2]\n",
    "    \n",
    "    #Â FIND SHARED USERS\n",
    "    u_common = pd.merge(users_item1, users_item2, on = 'user_id')\n",
    "    if len(u_common)==0:\n",
    "        return 0    \n",
    "    if(len(u_common)<min_common_users):\n",
    "        return 0 \n",
    "    \n",
    "    num = u_common['rating_x'].dot(u_common['rating_y'])\n",
    "    den = np.sqrt(u_common['rating_x'].dot(u_common['rating_x'])*u_common['rating_y'].dot(u_common['rating_y']))\n",
    "    adjcos = num/den\n",
    "    if(np.isnan(adjcos)):\n",
    "        return 0\n",
    "    return adjcos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rmse(y_pred, y_true):\n",
    "    \"\"\" Compute Root Mean Squared Error. \"\"\"\n",
    "    return np.sqrt(np.mean(np.power(y_pred - y_true, 2)))\n",
    "\n",
    "def evaluate(estimate_f,data_train,data_test):\n",
    "    \"\"\" RMSE-based predictive performance \"\"\"\n",
    "    ids_to_estimate = zip(data_test.user_id, data_test.item_id)\n",
    "    estimated = np.array([estimate_f(u,i) if u in data_train.user_id else 0 for (u,i) in ids_to_estimate ])\n",
    "    real = data_test.rating.values\n",
    "    return compute_rmse(estimated, real)\n",
    "\n",
    "def evaluate_k(estimate_f,data_train,data_test,k):\n",
    "    \"\"\" RMSE-based predictive performance. Takes the number k of nearest neighbors as input \"\"\"\n",
    "    ids_to_estimate = zip(data_test.user_id, data_test.item_id)\n",
    "    estimated = np.array([estimate_f(u,i,k) if u in data_train.user_id else 0 for (u,i) in ids_to_estimate ])\n",
    "    real = data_test.rating.values\n",
    "    return compute_rmse(estimated, real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CollaborativeFiltering:\n",
    "    \"\"\" Collaborative filtering using a custom sim(i,i'). \"\"\"\n",
    "    \n",
    "    def __init__(self,df, similarity=adjcos_similarity_items):\n",
    "        \"\"\" Constructor \"\"\"\n",
    "        self.sim_method=similarity# Gets recommendations for a person by using a weighted average\n",
    "        self.df=df\n",
    "        self.sim={}   \n",
    "        \n",
    "    def get_sim(self):\n",
    "        \"\"\" Return similarity for debugging reasons \"\"\" \n",
    "        return self.sim    \n",
    "        \n",
    "    def train(self):\n",
    "        \"\"\" Prepare data structures for estimation. Similarity matrix for items \"\"\"\n",
    "        all_items = set(self.df['item_id'])\n",
    "        for item1 in all_items:\n",
    "            self.sim.setdefault(item1, {})\n",
    "            a=data_train[data_train['item_id']==item1][['user_id']]\n",
    "            data_reduced=pd.merge(data_train,a,on='user_id')\n",
    "            for item2 in all_items:\n",
    "                \n",
    "                if item1==item2: continue\n",
    "                self.sim.setdefault(item2, {})\n",
    "                if(item1 in self.sim[item2]):continue\n",
    "                sim=self.sim_method(data_reduced,item1,item2)\n",
    "                if(sim<0):\n",
    "                    self.sim[item1][item2]=0\n",
    "                    self.sim[item2][item1]=0\n",
    "                else:\n",
    "                    self.sim[item1][item2]=sim\n",
    "                    self.sim[item2][item1]=sim\n",
    "        \n",
    "    def get_most_similar_items(self, item_id, k):\n",
    "        sorted_sim_of_item = sorted(self.sim[item_id].items(), key=operator.itemgetter(1), reverse = True)\n",
    "        most_similar_items = [sorted_sim_of_item[i][0] for i in range(k-1)]\n",
    "        return(most_similar_items)\n",
    "            \n",
    "    def predict_k(self, user_id, item_id, k):\n",
    "        \n",
    "        # Extract k most similar items\n",
    "        most_similar_items = set(self.get_most_similar_items(item_id, k))\n",
    "        \n",
    "        totals={}\n",
    "        user_items=self.df[self.df['user_id'] == user_id]\n",
    "        rating_num=0.0\n",
    "        rating_den=0.0\n",
    "        all_items=set(user_items['item_id'])\n",
    "        \n",
    "        # Intersection of k most similar items with items that have been commonly rated\n",
    "        intersect_items = most_similar_items & all_items\n",
    "        \n",
    "        for other in intersect_items:\n",
    "            if item_id==other: continue \n",
    "            rating_num += self.sim[item_id][other] * float(user_items[user_items['item_id']==other]['rating'])\n",
    "            rating_den += self.sim[item_id][other]\n",
    "\n",
    "        if rating_den==0: \n",
    "            if self.df.rating[self.df['user_id']==user_id].mean()>0:\n",
    "                # return the mean user rating if there is no similar for the computation\n",
    "                return self.df.rating[self.df['user_id']==user_id].mean()\n",
    "            else:\n",
    "                # else return mean item rating \n",
    "                return self.df.rating[self.df['item_id']==item_id].mean()\n",
    "        \n",
    "        return rating_num/rating_den\n",
    "\n",
    "    \n",
    "    def predict(self, user_id, item_id):\n",
    "        \n",
    "        totals={}\n",
    "        user_items=self.df[self.df['user_id'] == user_id]\n",
    "        rating_num=0.0\n",
    "        rating_den=0.0\n",
    "        all_items=set(user_items['item_id'])\n",
    "        \n",
    "        for other in all_items:\n",
    "            if item_id==other: continue \n",
    "            rating_num += self.sim[item_id][other] * float(user_items[user_items['item_id']==other]['rating'])\n",
    "            rating_den += self.sim[item_id][other]\n",
    "\n",
    "        if rating_den==0: \n",
    "            if self.df.rating[self.df['user_id']==user_id].mean()>0:\n",
    "                # return the mean user rating if there is no similar for the computation\n",
    "                return self.df.rating[self.df['user_id']==user_id].mean()\n",
    "            else:\n",
    "                # else return mean item rating \n",
    "                return self.df.rating[self.df['item_id']==item_id].mean()\n",
    "        \n",
    "        return rating_num/rating_den"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(111)\n",
    "\n",
    "def assign_to_set(df):\n",
    "    sampled_ids = np.random.choice(df.index,\n",
    "                                   size=np.int64(np.ceil(df.index.size * 0.01)),\n",
    "                                   replace=False)\n",
    "    df.loc[sampled_ids, 'for_testing'] = True\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data_set has 876661 ratings\n",
      "Test data set has 73339 ratings\n",
      "The dataset has  100  items\n",
      "   user_id  item_id     rating  for_testing\n",
      "0    13291       98  -0.670408        False\n",
      "1    19559        8   1.436404        False\n",
      "2    32928       50   1.711739        False\n",
      "3    34459       29 -10.000000        False\n",
      "4    68339       19   4.277970        False\n"
     ]
    }
   ],
   "source": [
    "### Entire data set\n",
    "data = pd.read_csv('./data/training.csv', sep=',')\n",
    "data['for_testing'] = False\n",
    "grouped = data.groupby('user_id', group_keys=False).apply(assign_to_set)\n",
    "data_train = data[grouped.for_testing == False]\n",
    "data_test = data[grouped.for_testing == True]\n",
    "\n",
    "print(\"Training data_set has \"+ str(data_train.shape[0]) +\" ratings\")\n",
    "print(\"Test data set has \"+ str(data_test.shape[0]) +\" ratings\")\n",
    "print(\"The dataset has \", data.item_id.nunique(), \" items\")\n",
    "\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>for_testing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19559</td>\n",
       "      <td>8</td>\n",
       "      <td>1.436404</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32928</td>\n",
       "      <td>50</td>\n",
       "      <td>1.711739</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34459</td>\n",
       "      <td>29</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>68339</td>\n",
       "      <td>19</td>\n",
       "      <td>4.277970</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7685</td>\n",
       "      <td>11</td>\n",
       "      <td>7.441743</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id     rating  for_testing\n",
       "1    19559        8   1.436404        False\n",
       "2    32928       50   1.711739        False\n",
       "3    34459       29 -10.000000        False\n",
       "4    68339       19   4.277970        False\n",
       "5     7685       11   7.441743        False"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_mean(user_id, df_train):\n",
    "    user = df_train[df_train[\"user_id\"] == user_id] \n",
    "    mean = user.rating.mean()\n",
    "    return(mean)\n",
    "    \n",
    "    \n",
    "def construct_user_mean_dict(df_train):\n",
    "    user_ids = df_train.user_id.unique()\n",
    "    \n",
    "    counter = 0\n",
    "    user_means = {}\n",
    "    for user in user_ids:\n",
    "        counter += 1\n",
    "        user_means[user] = get_user_mean(user, df_train)\n",
    "        if float(counter % 1000) == 0.0:\n",
    "            print(counter)\n",
    "    return(user_means)\n",
    "\n",
    "def predict_mean_ratings_on_test_set(df_train):\n",
    "    user_means = construct_user_mean_dict(df_train)\n",
    "\n",
    "    mean_ratings = []\n",
    "\n",
    "    for user in data_test.user_id:\n",
    "        try:\n",
    "            mean_ratings.append(user_means[user])\n",
    "        except:\n",
    "            mean_ratings.append(0.0)\n",
    "    return(mean_ratings)\n",
    "        \n",
    "compute_rmse(predict_mean_ratings_on_test_set(data_train), data_test.rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "reco_item_adjcos = CollaborativeFiltering(data, similarity=adjcos_similarity_items)\n",
    "reco_item_adjcos.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.9631772074794087"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reco_item_adjcos.predict(19559,8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_ratings_on_test_set_item_item_class(test):\n",
    "    rating_pred = []\n",
    "    counter = 0\n",
    "    for user_id, item_id in zip(test.user_id, test.item_id):\n",
    "        counter += 1\n",
    "        rating_pred.append(reco_item_adjcos.predict(user_id, item_id))\n",
    "        if float(counter % 1000) == 0.0:\n",
    "            print(counter)\n",
    "    return(rating_pred)\n",
    "\n",
    "def correct_for_NaNs(rating_pred):\n",
    "    rating_pred_ = pd.Series(test.rating_pred)\n",
    "    print(rating_pred_.isnull().sum(), \"NaNs encountered!\")\n",
    "    \n",
    "    rating_pred_[rating_pred_.isnull()] = 0\n",
    "    \n",
    "    return(rating_pred_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_ratings = predict_ratings_on_test_set_item_item_class(data_test)\n",
    "#test_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0680789900118981"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_rmse(data_test.rating, test_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n"
     ]
    }
   ],
   "source": [
    "submission_ratings = predict_ratings_on_test_set_item_item_class(target_user_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.tail()\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'id': np.arange(sample_submission.shape[0]),\n",
    "    'rating': submission_ratings\n",
    "})\n",
    "\n",
    "submission.tail()\n",
    "\n",
    "submission.to_csv('submission.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
